# Bug Report — Missing shap Dependency Breaks Explainability Module

## Summary
- **Scope/Area**: ml/explainability, dependencies, tests
- **Type**: Missing Dependencies — Severity: S3 (Medium)
- **Environment**:
  - Branch: main
  - Commit: 115c65ae8db2dc827003e144c2e70a9143417ce0
  - OS: Darwin 24.5.0
  - Python: 3.11-3.12

## Expected vs Actual
- **Expected**: ML explainability module works correctly with SHAP (SHapley Additive exPlanations) support
- **Actual**: Import fails with `ModuleNotFoundError: No module named 'shap'` when importing shap_explainer.py

## Steps to Reproduce
1. `PYTHONPATH=src poetry run python -c "import shap"`
2. Observe `ModuleNotFoundError: No module named 'shap'`
3. OR: `poetry run pytest src/alpha_pulse/tests/test_explainability.py`
4. Observe import failure during test collection (though currently masked by issue #116)

## Evidence

### Missing Dependency

**SHAP:**
- **Used in**:
  - `src/alpha_pulse/ml/explainability/shap_explainer.py:2` (`import shap`)
  - Line 81: `shap.TreeExplainer`
  - Line 97: `shap.DeepExplainer`
  - Line 110: `shap.GradientExplainer`
  - Line 120: `shap.LinearExplainer`
  - Line 144: `shap.sample`
  - Line 146: `shap.KernelExplainer`
  - Line 159: Instance checks for shap explainer types
- **Status**: ❌ NOT in pyproject.toml
- **Poetry check**: `Package shap not found`

### Error Stack Trace
```
$ PYTHONPATH=src poetry run python -c "import shap"
Traceback (most recent call last):
  File "<string>", line 1, in <module>
ModuleNotFoundError: No module named 'shap'
```

### Code Usage Analysis

**SHAP Explainer Module (`shap_explainer.py`):**
- Line 2: `import shap` (unconditional import)
- Lines 78-150: Extensive use of SHAP explainer classes:
  - `TreeExplainer` for tree-based models (XGBoost, LightGBM, RandomForest, etc.)
  - `DeepExplainer` for neural networks
  - `GradientExplainer` for neural networks (fallback)
  - `LinearExplainer` for linear models
  - `KernelExplainer` for generic models (fallback)
- Lines 181-419: SHAP value computation and visualization data generation

**Test Impact:**
- `src/alpha_pulse/tests/test_explainability.py` - imports explainability modules
- `src/alpha_pulse/tests/integration/test_feature_integration.py` - integration tests
- Note: Current test failure is masked by issue #116 (dataclass ordering error)

### Impact

**Affected Components:**
1. `SHAPExplainer` class (entire class unusable)
2. All explainability features that rely on SHAP
3. Model interpretability functionality
4. Feature importance analysis using SHAP values
5. Explainability tests

**Severity**: S3 (Medium)
- Explainability functionality broken
- Core ML explainability/interpretability unavailable
- Tests fail (currently masked by other import errors)
- Workaround exists: use other explainability methods (LIME, permutation importance)
- Not critical for trading operations but important for model validation and compliance

## Diagnosis Timeline

### T0: Detection/Context (2025-10-11 17:37:39Z)
- Issue #109 opened: "Missing shap dependency breaks explainability tests"
- Reported: `ModuleNotFoundError: No module named 'shap'`

### T1: Investigation (2025-10-13)
- Verified import in `shap_explainer.py` line 2
- Checked pyproject.toml: shap NOT present
- Confirmed with `poetry show shap`: Package not found
- Ran import test: Fails with ModuleNotFoundError

### T2: Scope Analysis (2025-10-13)
- Found shap used in 1 primary file (shap_explainer.py)
- Found references in 3 test/doc files
- Identified entire SHAPExplainer class broken (419 lines of code)
- Test suite issue masked by issue #116 (dataclass ordering)

### T3: Root Cause Identified (2025-10-13)
- **Root Cause**: Required ML explainability dependency (shap) not declared in pyproject.toml
- **Code Impact**: SHAP-based explainability completely non-functional
- **Test Impact**: test_explainability.py cannot import (masked by other issue)

## Root Cause Analysis

### 5 Whys

1. **Why does the explainability module fail to import?**
   - Because Python cannot import the shap module

2. **Why can't Python import shap?**
   - Because shap is not installed in the Poetry environment

3. **Why isn't shap installed?**
   - Because it is not declared as a dependency in pyproject.toml

4. **Why wasn't it declared?**
   - Possible reasons:
     a) Code was written assuming shap would be manually installed
     b) Dependency was overlooked during explainability feature implementation
     c) Originally intended as optional but not properly gated with try/except
     d) Development environment had shap installed globally/separately

5. **Why wasn't this caught earlier?**
   - Tests may not be running in CI consistently for explainability module
   - Test failures currently masked by issue #116 (dataclass ordering error)
   - Developer environments may have had shap installed globally
   - No dependency audit or import validation in CI pipeline

### Causal Chain

**Explainability Code Written** → **SHAP Import Added** → **Dependency NOT Added to pyproject.toml** → **Poetry Install Doesn't Include shap** → **Import Fails** → **SHAP Explainability Broken**

### Change-Based Analysis

The SHAP explainer is a sophisticated ML interpretability implementation that requires the specialized `shap` library for Shapley value computations. The code imports it unconditionally (no try/except), indicating it was considered a required dependency. However, it was never added to pyproject.toml, suggesting:
- The code may have been written in an environment where shap was already installed
- Or there was incomplete dependency management during explainability feature development
- No validation that all imports have corresponding dependency declarations

## Remediation

### Immediate Fix

Add the missing dependency to pyproject.toml:

```toml
[tool.poetry.dependencies]
shap = "^0.46.0"
```

Then run:
```bash
poetry add shap
poetry install
```

### Alternative: Optional Dependencies (If Desired)

If SHAP explainability is meant to be optional, wrap imports with graceful degradation:

```python
# In shap_explainer.py
try:
    import shap
    SHAP_AVAILABLE = True
except ImportError:
    SHAP_AVAILABLE = False
    shap = None

class SHAPExplainer:
    def __init__(self, model: Any, config: Optional[SHAPConfig] = None):
        if not SHAP_AVAILABLE:
            raise ImportError(
                "SHAP is not installed. Install with: pip install shap\n"
                "Or use Poetry: poetry add shap"
            )
        # ... rest of implementation
```

### Recommended Solution

**Add as required dependency** because:
1. Entire `SHAPExplainer` class (419 lines) is entirely dependent on it
2. No fallback logic currently exists
3. SHAP is the de facto standard for ML model explainability
4. Important for model validation, compliance, and interpretability
5. Unconditional import indicates it was designed as required

### Risk & Rollback Considerations

- **Risk**: Very Low - Adding standard ML explainability dependency
- **Package Size**:
  - shap: ~10MB (relatively lightweight)
  - Depends on: numpy, scipy, pandas, scikit-learn (already installed)
- **Compatibility**: Works with Python 3.8+ (compatible with project's 3.11-3.12)
- **Rollback**: Simply remove from pyproject.toml if needed
- **Impact**: Fixes broken explainability functionality, unblocks interpretability features

## Validation & Prevention

### Test Plan
1. ✅ Identify shap usage in codebase (found in 1 primary file)
2. ✅ Verify shap NOT in pyproject.toml
3. ⬜ Add shap to pyproject.toml
4. ⬜ Run `poetry install`
5. ⬜ Verify import works: `python -c "import shap; print(shap.__version__)"`
6. ⬜ Resolve issue #116 (dataclass ordering) to unblock tests
7. ⬜ Run explainability tests: `poetry run pytest src/alpha_pulse/tests/test_explainability.py -v`
8. ⬜ Run full test suite to ensure no regressions

### Commands
```bash
# Add dependency
poetry add shap

# Verify installation
poetry show shap

# Test import
PYTHONPATH=src poetry run python -c "import shap; print('SHAP version:', shap.__version__)"

# Run tests (after fixing issue #116)
PYTHONPATH=src poetry run pytest src/alpha_pulse/tests/test_explainability.py -v
```

### Regression Prevention
- **Dependency Audit**: Add CI step to verify all imports have corresponding dependencies
- **Import Validation**: Create script to scan for imports and cross-reference with pyproject.toml
- **Pre-commit Hook**: Validate dependency completeness before commits
- **Documentation**: Document all ML dependencies and their purposes

### Example Validation Script
```python
# scripts/validate_dependencies.py
import ast
import sys
from pathlib import Path
import toml

def get_imports(file_path):
    with open(file_path) as f:
        tree = ast.parse(f.read())
    imports = set()
    for node in ast.walk(tree):
        if isinstance(node, ast.Import):
            for alias in node.names:
                imports.add(alias.name.split('.')[0])
        elif isinstance(node, ast.ImportFrom):
            if node.module:
                imports.add(node.module.split('.')[0])
    return imports

def get_declared_dependencies():
    pyproject = toml.load('pyproject.toml')
    return set(pyproject['tool']['poetry']['dependencies'].keys())

# Check all imports against dependencies
# Fail if any import doesn't have corresponding dependency
```

## Conclusion

This is a **GENUINE BUG** - critical ML explainability dependency (shap) is used extensively but not declared in pyproject.toml.

**Impact:**
- ❌ `SHAPExplainer` class: Completely broken (419 lines)
- ❌ SHAP-based explainability: Unavailable
- ❌ Model interpretability: Severely limited
- ❌ Feature importance analysis: Missing SHAP-based methods
- ❌ Explainability tests: Cannot import (currently masked by issue #116)

**Fix Required:**
```bash
poetry add shap
```

**Note:** This issue is independent of issue #116 (dataclass ordering), but both need to be fixed for explainability tests to pass.

## Ownership & Next Steps

- **Owner(s)**: Repository maintainers (blackms)
- **Priority**: Medium - Explainability functionality broken (not critical for trading but important for compliance)
- **Dependencies/links**:
  - Issue #109: https://github.com/blackms/AlphaPulse/issues/109
  - Related issue #116: Dataclass ordering blocks tests
  - Files affected:
    - `src/alpha_pulse/ml/explainability/shap_explainer.py`
    - `src/alpha_pulse/tests/test_explainability.py`
    - `src/alpha_pulse/tests/integration/test_feature_integration.py`

### Checklist
- [x] Reproducible steps verified (Import error confirmed)
- [x] Evidence attached/linked (Import traces, file analysis)
- [x] RCA written and reviewed (5 Whys, causal chain complete)
- [ ] Dependency added to pyproject.toml
- [ ] Tests passing
- [ ] Issue closed

---

**Generated**: 2025-10-13
**Analyzed by**: Claude Code (BUG-PROTO.yaml workflow)
**Status**: ANALYSIS COMPLETE - GENUINE MISSING DEPENDENCY (Add shap)
